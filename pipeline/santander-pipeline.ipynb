{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pipeline.py\n# ============================================================\n# Santander Customer Satisfaction - End-to-End ML Pipeline\n# ============================================================\n\nimport argparse\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\n\n# ------------------------------------------------------------\n# 1. Data Loading\n# ------------------------------------------------------------\ndef load_data(train_path, test_path):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    return train, test\n\n\n# ------------------------------------------------------------\n# 2. Basic Feature Cleaning\n# ------------------------------------------------------------\ndef basic_cleaning(train, test):\n    # Remove zero-variance features\n    remove_cols = [c for c in train.columns if c != \"TARGET\" and train[c].var() == 0]\n    train.drop(columns=remove_cols, inplace=True)\n    test.drop(columns=remove_cols, inplace=True)\n\n    # Remove sparse features (99% quantile == 0)\n    sparse_cols = [\n        c for c in train.columns\n        if c != \"TARGET\" and np.percentile(train[c], 99) == 0\n    ]\n    train.drop(columns=sparse_cols, inplace=True)\n    test.drop(columns=sparse_cols, inplace=True)\n\n    return train, test\n\n\n# ------------------------------------------------------------\n# 3. Domain Feature Engineering\n# ------------------------------------------------------------\ndef feature_engineering(train, test):\n    # VAR3\n    for df in [train, test]:\n        df[\"var3\"].replace(-999999, 2, inplace=True)\n\n    # VAR15\n    for df in [train, test]:\n        df[\"var15_below_23\"] = (df[\"var15\"] < 23).astype(int)\n\n    # VAR38\n    q975 = np.quantile(train[\"var38\"], 0.975)\n    for df in [train, test]:\n        df[\"var38_clipped\"] = df[\"var38\"].clip(upper=q975)\n        df[\"var38_log\"] = np.log1p(df[\"var38_clipped\"])\n\n    # log transform imp / saldo\n    for prefix in [\"imp\", \"saldo\"]:\n        cols = [c for c in train.columns if prefix in c]\n        for df in [train, test]:\n            for c in cols:\n                mask = df[c] > 0\n                df.loc[mask, c] = np.log1p(df.loc[mask, c])\n\n    # count zero / non-zero\n    feature_cols = [c for c in train.columns if c not in [\"ID\", \"TARGET\"]]\n    for df in [train, test]:\n        df[\"no_zeros\"] = (df[feature_cols] == 0).sum(axis=1)\n        df[\"no_nonzeros\"] = (df[feature_cols] != 0).sum(axis=1)\n\n    return train, test\n\n\n# ------------------------------------------------------------\n# 4. Prepare Train / Test Matrix\n# ------------------------------------------------------------\ndef prepare_matrix(train, test):\n    X = train.drop(columns=[\"ID\", \"TARGET\"])\n    y = train[\"TARGET\"].values\n    X_test = test.drop(columns=[\"ID\"])\n    test_id = test[\"ID\"].values\n    return X, y, X_test, test_id\n\n\n# ------------------------------------------------------------\n# 5. Scaling\n# ------------------------------------------------------------\ndef scale_features(X, X_test):\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    X_test_scaled = scaler.transform(X_test)\n    return X_scaled, X_test_scaled\n\n\n# ------------------------------------------------------------\n# 6. Model Training\n# ------------------------------------------------------------\ndef train_model(X, y):\n    X_tr, X_val, y_tr, y_val = train_test_split(\n        X, y, test_size=0.15, stratify=y, random_state=42\n    )\n\n    model = xgb.XGBClassifier(\n        n_estimators=1000,\n        learning_rate=0.01,\n        max_depth=5,\n        subsample=0.9,\n        colsample_bytree=0.5,\n        gamma=5,\n        reg_alpha=0.3,\n        objective=\"binary:logistic\",\n        eval_metric=\"auc\",\n        random_state=42,\n        n_jobs=-1\n    )\n\n    model.fit(\n        X_tr, y_tr,\n        eval_set=[(X_val, y_val)],\n        early_stopping_rounds=50,\n        verbose=False\n    )\n\n    val_pred = model.predict_proba(X_val)[:, 1]\n    auc = roc_auc_score(y_val, val_pred)\n    print(f\"‚úÖ Validation AUC: {auc:.4f}\")\n\n    return model\n\n\n# ------------------------------------------------------------\n# 7. Main Pipeline\n# ------------------------------------------------------------\ndef main(args):\n    print(\"üöÄ Loading data...\")\n    train, test = load_data(args.train, args.test)\n\n    print(\"üßπ Basic cleaning...\")\n    train, test = basic_cleaning(train, test)\n\n    print(\"üß† Feature engineering...\")\n    train, test = feature_engineering(train, test)\n\n    print(\"üìê Preparing matrices...\")\n    X, y, X_test, test_id = prepare_matrix(train, test)\n\n    print(\"‚öñÔ∏è Scaling features...\")\n    X_scaled, X_test_scaled = scale_features(X, X_test)\n\n    print(\"ü§ñ Training model...\")\n    model = train_model(X_scaled, y)\n\n    print(\"üì§ Predicting test set...\")\n    preds = model.predict_proba(X_test_scaled)[:, 1]\n\n    submission = pd.DataFrame({\n        \"ID\": test_id,\n        \"TARGET\": preds\n    })\n    submission.to_csv(args.output, index=False)\n\n    print(f\"‚úÖ Submission saved to {args.output}\")\n\n\n# ------------------------------------------------------------\n# Entry\n# ------------------------------------------------------------\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--train\", type=str, required=True, help=\"Path to train.csv\")\n    parser.add_argument(\"--test\", type=str, required=True, help=\"Path to test.csv\")\n    parser.add_argument(\"--output\", type=str, default=\"submission.csv\")\n\n    args = parser.parse_args()\n    main(args)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}